{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from itertools import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    file = codecs.open(filename,'r','utf-8')\n",
    "    data = []\n",
    "    label = []\n",
    "    for line in islice(file,0,None):\n",
    "        line = line.strip().split(',')\n",
    "        #print (\"reading data....\")\n",
    "        data.append([float(i) for i in line[1:-1]])\n",
    "        label.append(line[-1])\n",
    "    x = np.array(data)\n",
    "    y = np.array(label)\n",
    "    print (x)\n",
    "    print (y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from itertools import *\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x_train,y_label):  ####为保证分类结果的准确度可靠，采用十折交叉验证\n",
    "    ##########logisticRegression################\n",
    "    clf1 = LogisticRegression()\n",
    "    score1 = model_selection.cross_val_score(clf1,x_train,y_label,cv=10,scoring=\"accuracy\")\n",
    "    x = [int(i) for i in range(1,11)]\n",
    "    y = score1\n",
    "    pl.ylabel(u'Accuracy')\n",
    "    pl.xlabel(u'times')\n",
    "    pl.plot(x,y,label='LR')\n",
    "    pl.legend()\n",
    "    pl.savefig(\"1_LR.png\")\n",
    "    #pl.show()\n",
    "    print ('The accuracy of LogisticRegression:')\n",
    "    print (np.mean(score1))\n",
    "    ###############SVM（linear)###################\n",
    "    clf2 = svm.LinearSVC(random_state=2016)\n",
    "    score2 = model_selection.cross_val_score(clf2,x_train,y_label,cv=10,scoring='accuracy')\n",
    "    #print score2\n",
    "    print ('The accuracy of linearSVM:')\n",
    "    print ((np.mean(score2)))\n",
    "    x = [int(i) for i in range(1, 11)]\n",
    "    y = score2\n",
    "    pl.ylabel(u'Accuracy')\n",
    "    pl.xlabel(u'times')\n",
    "    pl.plot(x, y,label='SVM')\n",
    "    pl.legend()\n",
    "    pl.savefig(\"2_SVM.png\")\n",
    "    #pl.show()\n",
    "    #################Naive Bayes################\n",
    "    clf3 = GaussianNB()\n",
    "    score3 =  model_selection.cross_val_score(clf3,x_train,y_label,cv=10,scoring='accuracy')\n",
    "    print (\"The accuracy of Naive Bayes:\")\n",
    "    print ((np.mean(score3)))\n",
    "    x = [int(i) for i in range(1, 11)]\n",
    "    y = score3\n",
    "    pl.ylabel(u'Accuracy')\n",
    "    pl.xlabel(u'times')\n",
    "    pl.plot(x, y,label='NB')\n",
    "    pl.legend()\n",
    "    pl.savefig(\"3_NB.png\")\n",
    "    #pl.show()\n",
    "    ################DecidionTree###############\n",
    "    clf4 = tree.DecisionTreeClassifier()\n",
    "    score4 = model_selection.cross_val_score(clf4,x_train,y_label,cv=10,scoring=\"accuracy\")\n",
    "    print ('The accuracy of DB:')\n",
    "    print (np.mean(score4))\n",
    "    x = [int(i) for i in range(1, 11)]\n",
    "    y = score4\n",
    "    pl.ylabel(u'Accuracy')\n",
    "    pl.xlabel(u'times')\n",
    "    pl.plot(x, y,label='DB')\n",
    "    pl.legend()\n",
    "    pl.savefig(\"4_DB.png\")\n",
    "    #pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.26793200e-01   2.18446744e-01   2.19660232e-01 ...,   6.94287400e-03\n",
      "    1.81226200e-03   3.60711000e-03]\n",
      " [  2.25946800e-01   2.23718028e-01   2.11285602e-01 ...,   3.15725800e-03\n",
      "    3.02607200e-03   3.65655900e-03]\n",
      " [  2.26845435e-01   2.13040584e-01   2.23656706e-01 ...,   4.58657700e-03\n",
      "    2.49244500e-03   2.58202800e-03]\n",
      " ..., \n",
      " [  2.50269679e-01   2.25755263e-01   2.19862111e-01 ...,   6.46997200e-03\n",
      "    2.69498400e-03   5.55240400e-03]\n",
      " [  2.28760650e-01   2.27787514e-01   2.15767226e-01 ...,   2.25815900e-03\n",
      "    1.92547400e-03   2.42930100e-03]\n",
      " [  2.28544563e-01   2.19564312e-01   2.24675769e-01 ...,   1.26475000e-04\n",
      "    3.12649000e-04   1.63584800e-03]]\n",
      "['0' '0' '0' ..., '1' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_data('feature/feature_dpp_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of LogisticRegression:\n",
      "0.648052959502\n",
      "The accuracy of linearSVM:\n",
      "0.741026306681\n",
      "The accuracy of Naive Bayes:\n",
      "0.677829698858\n",
      "The accuracy of DB:\n",
      "0.667739702319\n"
     ]
    }
   ],
   "source": [
    "train(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码是使用了 Random Forest 并且得到相应的特征重要性排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of RF:\n",
      "0.713257182416\n"
     ]
    }
   ],
   "source": [
    "clf5 = RandomForestClassifier(oob_score=True)\n",
    "score5 = model_selection.cross_val_score(clf5,X,Y,cv=10,scoring='accuracy')\n",
    "print (\"The accuracy of RF:\")\n",
    "print (np.mean(score5))\n",
    "x = [int(i) for i in range(1,11)]\n",
    "y = score5\n",
    "pl.ylabel(u'Accuracy')\n",
    "pl.xlabel(u'times')\n",
    "pl.plot(x, y,label='RF')\n",
    "pl.legend()\n",
    "pl.savefig(\"5_RF.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675348837209\n",
      "[ 0.00727269  0.03917914  0.00183214  0.00864343  0.00636981  0.01985771\n",
      "  0.01438643  0.01307632  0.00544092  0.00388311  0.0052318   0.03359874\n",
      "  0.00248731  0.00850119  0.00518442  0.00735216  0.00717428  0.01111966\n",
      "  0.00567053  0.00363808  0.00360843  0.01623382  0.00582543  0.0095755\n",
      "  0.00394681  0.01120963  0.00489376  0.0163879   0.00401742  0.00626596\n",
      "  0.01035854  0.02811908  0.0059774   0.00426501  0.00655986  0.00681584\n",
      "  0.00506444  0.01056748  0.00770572  0.00865614  0.00602253  0.00936824\n",
      "  0.00750197  0.01721424  0.00715376  0.00432691  0.00267434  0.01315148\n",
      "  0.01014691  0.00310386  0.00475892  0.00616973  0.00861774  0.00217542\n",
      "  0.00637467  0.00452963  0.00891596  0.01383442  0.0048814   0.00347679\n",
      "  0.00017907  0.00785054  0.00685046  0.00681543  0.00907719  0.0067861\n",
      "  0.00632904  0.02690681  0.00608364  0.00152607  0.02059082  0.00674196\n",
      "  0.0036256   0.00356205  0.00929343  0.00565973  0.00199747  0.00544261\n",
      "  0.00853257  0.00211648  0.00686413  0.05020724  0.00497257  0.00577207\n",
      "  0.00623675  0.02638727  0.00406018  0.00180859  0.00615916  0.00548158\n",
      "  0.00609685  0.01337255  0.00614669  0.00406012  0.00457468  0.0060852\n",
      "  0.00319491  0.00684094  0.00385536  0.00499891  0.01020155  0.00794665\n",
      "  0.00947049  0.00189602  0.00389684  0.0038024   0.00441898  0.01273716\n",
      "  0.00292606  0.0030122   0.0093751   0.00650636  0.01244529  0.01155399\n",
      "  0.004068    0.00550644  0.00418323  0.01044913  0.01347702  0.00863132]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:451: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:456: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True)\n",
    "rf.fit(X,Y)\n",
    "score = rf.oob_score_\n",
    "print (score)\n",
    "importances = rf.feature_importances_\n",
    "print (importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81, 1, 11, 31, 67, 85, 70, 5, 43, 27, 21, 6, 57, 118, 91, 47, 7, 107, 112, 113, 25, 17, 37, 117, 30, 100, 48, 23, 102, 110, 41, 74, 64, 56, 39, 3, 119, 52, 78, 13, 101, 61, 38, 42, 15, 0, 16, 44, 80, 62, 97, 35, 63, 65, 71, 34, 111, 54, 4, 66, 29, 84, 51, 88, 92, 90, 95, 68, 40, 32, 22, 83, 18, 75, 115, 89, 77, 8, 10, 14, 36, 99, 82, 26, 58, 50, 94, 55, 106, 45, 33, 116, 114, 86, 93, 28, 24, 104, 9, 98, 105, 19, 72, 20, 73, 59, 96, 49, 109, 108, 46, 12, 53, 79, 76, 103, 2, 87, 69, 60]\n"
     ]
    }
   ],
   "source": [
    "#得到特征重要性\n",
    "index_importances = []\n",
    "importances = list(importances)\n",
    "while(max(importances)>0):\n",
    "    index_importances.append(importances.index(max(importances)))\n",
    "    importances[importances.index(max(importances))]=0\n",
    "print(index_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总共测试了不同的分类算法\n",
    "发现SVM性能最好，准确率最高\n",
    "（但是得不到论文中那么高的准确率！！！）\n",
    "最高的是SVM 准确率在74%左右"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
